{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ChatGPT in Jupyter Notebook\n",
    "\n",
    "As a trainer, you might have prepared a set of questions to ask your students. This will increase interactivity. Thinking upfront about what to ask is a valuable skill, that will pay off during the training (you don't need to invent questions on the fly).\n",
    "\n",
    "You might want to use ChatGPT to generate answers to these questions. This can help you with brainstorming, adding more questions, and getting a better understanding of the topic.\n",
    "\n",
    "This notebook shows how to do this.\n",
    "\n",
    "**Setup**\n",
    "\n",
    "The first cell below setups the required environment. It will install the required libraries and define a function to generate answers. Fetch the OPENAI_API_KEY from the dashboard and paste it in a new file called '.env' in the same directory as this notebook.\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "start_sequence = \" Keep it short with a bulleted list. The context for this question is Microsoft Azure technology.\"\n",
    "\n",
    "def askGPT(question):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=question + start_sequence,\n",
    "        temperature=0.7,\n",
    "        max_tokens=300,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    print(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's a list of questions that I prepared for a particular topic (introduction to data engineering on Azure):**\n",
    "\n",
    "- Share an example of structured/unstructured/semi-structured data. \n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/training/modules/choose-storage-approach-in-azure/2-classify-data)\n",
    "- A Parquet file would be an example of structured/unstructured/semi-structured?\n",
    "  [ðŸ”—](https://www.youtube.com/watch?v=auNAzC3AU18&t=152s)\n",
    "- What's the difference between data integration/data transformation/data consolidation?\n",
    "  [ðŸ”—](https://cyclr.com/blog/data-consolidation-through-integration)\n",
    "- Why would I use a programming language like Python to transform data? \n",
    "  [ðŸ”—](https://www.simplilearn.com/why-python-is-essential-for-data-analysis-article#why_is_python_essential_for_data_analysis)\n",
    "- Why would I consider Spark? \n",
    "  [ðŸ”—](https://spark.apache.org/)\n",
    "- Why would I consider using a data lake?\n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/azure/architecture/data-guide/scenarios/data-lake)\n",
    "- What is the difference between a data lake and a data warehouse? \n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/azure/architecture/data-guide/scenarios/data-lake#when-to-use-a-data-lake)\n",
    "- Why is it a bad idea to mix reporting/analytics and OLTP databases?\n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/azure/architecture/data-guide/relational-data/online-transaction-processing#challenges)\n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/azure/architecture/data-guide/relational-data/online-analytical-processing#challenges)\n",
    "- What is the difference between Azure Synapse Analytics Pipelines and Azure Data Factory?\n",
    "  [ðŸ”—](https://learn.microsoft.com/en-us/azure/synapse-analytics/data-integration/concepts-data-factory-differences)\n",
    "\n",
    "Below, I have a cell ready to use for each question. You can copy/paste the question into the cell and run it to get an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-Reporting and analytics databases are optimized for read-heavy workloads, while OLTP databases are optimized for write-heavy workloads.\n",
      "Mixing them together can lead to performance issues and contention.\n",
      "-OLTP databases are designed to handle many transactions quickly, while reporting and analytics databases are designed to store large volumes of data for longer periods of time.\n",
      "-OLTP databases are usually optimized for short transactions and have more stringent security requirements, while reporting and analytics databases are optimized for longer transactions and have less stringent security requirements.\n",
      "-Mixing the two databases can lead to data integrity issues, as well as increased complexity for the administrators.\n"
     ]
    }
   ],
   "source": [
    "askGPT(\"Why is it a bad idea to mix reporting/analytics and OLTP databases?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
